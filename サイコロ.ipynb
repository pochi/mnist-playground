{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "サイコロ.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "GBSJOv2PI-yy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from pandas import concat\n",
        "from pandas import DataFrame\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import collections\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWvjEU5na8vJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [演繹法]コンピュータ上でサイコロを作る\n",
        "\n",
        "- 1から6の値をランダムに出力する"
      ]
    },
    {
      "metadata": {
        "id": "TSx3bACDkBcr",
        "colab_type": "code",
        "outputId": "5058b27f-1e4c-499d-b269-77d92a272990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "cell_type": "code",
      "source": [
        "# サイコロのように振る舞う乱数を100個生成する\n",
        "roll_dices = [randint(0,5) + 1 for _ in range(100)]\n",
        "\n",
        "print(\"100回施行した結果\")\n",
        "print(roll_dices)\n",
        "\n",
        "print(\"各目が出た結果\")\n",
        "count_result = collections.Counter(roll_dices)\n",
        "for k, v in sorted(count_result.items()):\n",
        "    print(str(k) + \": \" + str(v) + \"(\" + str(v)  + \" %)\")\n",
        "    \n",
        "sns.distplot(roll_dices, kde=False, rug=False, bins=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dca435364220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroll_dices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"100回施行した結果\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroll_dices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-dca435364220>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroll_dices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"100回施行した結果\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroll_dices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'randint' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3MF1HYw7Gn6N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [帰納法]コンピュータ上でサイコロを作る\n",
        "\n",
        "- 100回サイコロを試行して最も出やすい目を選択する"
      ]
    },
    {
      "metadata": {
        "id": "M1FE3ZsZGkHz",
        "colab_type": "code",
        "outputId": "f601ecf0-ef49-419b-e14e-84ffb824e262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "cell_type": "code",
      "source": [
        "def induction_dice():\n",
        "  # 100回施行した結果から最も出やすい出現数を選ぶ\n",
        "  roll_dices = [randint(0,5) + 1 for _ in range(100)]\n",
        "  count_result = collections.Counter(roll_dices)\n",
        "  max_key, _ = max(count_result.items(), key=lambda x: x[1])\n",
        "  return max_key\n",
        "  \n",
        "roll_dices = [induction_dice() for _ in range(100)]\n",
        "\n",
        "print(\"100回試行した結果\")\n",
        "print(roll_dices)\n",
        "\n",
        "print(\"各目が出た結果\")\n",
        "count_result = collections.Counter(roll_dices)\n",
        "for k, v in sorted(count_result.items()):\n",
        "    print(str(k) + \": \" + str(v) + \"(\" + str(v)  + \" %)\")\n",
        "    \n",
        "sns.distplot(roll_dices, kde=False, rug=False, bins=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100回試行した結果\n",
            "[4, 1, 1, 5, 4, 6, 4, 3, 4, 1, 1, 4, 3, 5, 3, 6, 6, 3, 4, 1, 1, 4, 1, 6, 4, 5, 4, 5, 1, 1, 5, 4, 4, 6, 5, 4, 5, 6, 5, 4, 5, 3, 2, 4, 6, 3, 3, 4, 1, 1, 1, 5, 2, 3, 5, 5, 3, 4, 6, 6, 3, 4, 3, 3, 5, 5, 3, 1, 1, 1, 4, 5, 6, 3, 3, 5, 6, 2, 1, 4, 2, 3, 4, 2, 3, 2, 6, 4, 5, 2, 2, 4, 2, 1, 1, 4, 3, 2, 3, 2]\n",
            "各目が出た結果\n",
            "1: 18(18 %)\n",
            "2: 11(11 %)\n",
            "3: 19(19 %)\n",
            "4: 23(23 %)\n",
            "5: 17(17 %)\n",
            "6: 12(12 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
            "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
            "  alternative=\"'density'\", removal=\"3.1\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ff35ceb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvgCQTHwBIJn4AkAy8QWAZP8HEdtj7HcjzGoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TNfVplb1bQP3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [帰納法]コンピュータ上で深層学習を利用してサイコロを作る\n",
        "\n",
        "- ランダムな数字のデータを大量に作る(generate_data関数)\n",
        "- modelブロックでニューラルネットワークを定義\n",
        "- 学習を回す\n",
        "- 学んだ内容を推論する"
      ]
    },
    {
      "metadata": {
        "id": "ZxHq86tOJJ_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sequence(length=100):\n",
        "    return [randint(0, 5) for _ in range(length)]\n",
        "\n",
        "def one_hot_decode(encoded_seq):\n",
        "    return [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "def generate_data():\n",
        "    sequence = generate_sequence()\n",
        "    encoded = np_utils.to_categorical(sequence, num_classes=6)\n",
        "    df = DataFrame(encoded)\n",
        "    df = concat([df.shift(4), df.shift(3), df.shift(2), df.shift(1), df], axis=1)\n",
        "    values = df.values\n",
        "    values = values[5:,:]\n",
        "    X = values.reshape(len(values), 5, 6)\n",
        "    y = encoded[4:-1,:]\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJCh3mvTJRo0",
        "colab_type": "code",
        "outputId": "98f7a256-1b41-4fa0-904f-1b4c8f4077c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50, batch_input_shape=(5, 5, 6), stateful=True))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (5, 50)                   11400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (5, 6)                    306       \n",
            "=================================================================\n",
            "Total params: 11,706\n",
            "Trainable params: 11,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nMRQQcEkgAfE",
        "colab_type": "code",
        "outputId": "c2690c6b-9ff7-43bd-9ce4-1df499164229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10381
        }
      },
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "for i in range(300):\n",
        "    X, y = generate_data()\n",
        "    model.fit(X, y, epochs=1, batch_size=5, verbose=2, shuffle=False)\n",
        "    model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " - 3s - loss: 1.8086 - acc: 0.1368\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7722 - acc: 0.1895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7757 - acc: 0.2000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7470 - acc: 0.2526\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.7251 - acc: 0.3263\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6971 - acc: 0.3684\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6623 - acc: 0.3684\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6765 - acc: 0.3895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6208 - acc: 0.3684\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6152 - acc: 0.3579\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5741 - acc: 0.4421\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.5326 - acc: 0.4000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.6046 - acc: 0.4105\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3492 - acc: 0.4632\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3789 - acc: 0.5158\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.3684 - acc: 0.5158\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.2898 - acc: 0.5158\n",
            "Epoch 1/1\n",
            " - 0s - loss: 1.1043 - acc: 0.6211\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9276 - acc: 0.7053\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9997 - acc: 0.7263\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.9030 - acc: 0.7474\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8523 - acc: 0.7579\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.8212 - acc: 0.7895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6405 - acc: 0.9053\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6024 - acc: 0.8842\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.6169 - acc: 0.8947\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.4811 - acc: 0.9579\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.4714 - acc: 0.9368\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.3736 - acc: 0.9895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.3689 - acc: 0.9895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.3424 - acc: 0.9789\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.2697 - acc: 0.9895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.2223 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.2229 - acc: 0.9895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1795 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1543 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1678 - acc: 0.9895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1460 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1430 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1243 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1100 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.1020 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0937 - acc: 0.9895\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0811 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0693 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0725 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0546 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0688 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0553 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0536 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0476 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0443 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0434 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0399 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0369 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0332 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0302 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0339 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0321 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0287 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0290 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0245 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0300 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0242 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0255 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0240 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0229 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0211 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0211 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0239 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0181 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0188 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0162 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0175 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0150 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0135 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0143 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0134 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0124 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0136 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0132 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0135 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0129 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0125 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0114 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0106 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0101 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0115 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0103 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0095 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0097 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0110 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0099 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0093 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0087 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0069 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0069 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0068 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0062 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0050 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0044 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0023 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0021 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0019 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.0226e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.5279e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.5040e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.7788e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.9083e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.4505e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.7934e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.3146e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.0905e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.0585e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.4482e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.1268e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 9.1462e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.0941e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.2841e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.2117e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.0970e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.2792e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.9090e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.7227e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.0308e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.1760e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.7904e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.6446e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 8.0323e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.9454e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.7213e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.0493e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.2870e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.4723e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 7.2281e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.7493e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.6637e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.4240e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.8962e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.8246e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.6941e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.5196e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.0535e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.9082e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.7572e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.3065e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.8395e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.8512e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.0380e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.2965e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.7753e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 6.3907e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.9776e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.0156e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.4792e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.1530e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.9892e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.0377e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.4450e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.5114e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.3507e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.5808e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.1983e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.9898e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.7309e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.4520e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.0270e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.8143e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 5.1695e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.2752e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.2469e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.6628e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.8476e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 3.8436e-04 - acc: 1.0000\n",
            "Epoch 1/1\n",
            " - 0s - loss: 4.3555e-04 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "19XJLH7EJYmA",
        "colab_type": "code",
        "outputId": "bcfeb787-cf4c-49d5-a9fa-29a09eafc88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "cell_type": "code",
      "source": [
        "X, y = generate_data()\n",
        "predicts = model.predict(X, batch_size=5)\n",
        "roll_dices = [predict + 1 for predict in one_hot_decode(predicts)]\n",
        "\n",
        "print(\"100回試行した結果\")\n",
        "print(roll_dices)\n",
        "\n",
        "print(\"各目が出た結果\")\n",
        "count_result = collections.Counter(roll_dices)\n",
        "for k, v in sorted(count_result.items()):\n",
        "    print(str(k) + \": \" + str(v) + \"(\" + str(v)  + \" %)\")\n",
        "    \n",
        "sns.distplot(roll_dices, kde=False, rug=False, bins=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100回試行した結果\n",
            "[3, 4, 2, 6, 2, 1, 2, 2, 3, 4, 5, 3, 1, 6, 2, 4, 4, 4, 5, 3, 1, 6, 4, 2, 4, 3, 6, 6, 3, 5, 4, 3, 6, 4, 5, 6, 1, 3, 2, 6, 1, 2, 2, 3, 2, 3, 3, 4, 2, 1, 2, 2, 6, 6, 1, 5, 6, 1, 5, 2, 6, 4, 1, 2, 5, 5, 5, 1, 5, 6, 4, 5, 6, 5, 3, 3, 4, 4, 6, 2, 2, 3, 6, 6, 4, 2, 5, 3, 3, 3, 2, 3, 6, 1, 3]\n",
            "各目が出た結果\n",
            "1: 11(11 %)\n",
            "2: 19(19 %)\n",
            "3: 19(19 %)\n",
            "4: 15(15 %)\n",
            "5: 13(13 %)\n",
            "6: 18(18 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
            "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
            "  alternative=\"'density'\", removal=\"3.1\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ff3508908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGB9JREFUeJzt3X9MVff9x/EXcnfLEKqg96L9YV2Y\nWzudUzedyGqVoVaSdnUrBQ2om9lm1fljorXdVkmoGoyZndbUltou03Vlo83Cmq6YGk0ai2i7Lg67\nhNKmBpnDC14NBInK+P6x7PZLQGjPPcj7cp6Pv7j3cD/3fT/09Ok9CsR1dXV1CQAAmDFssAcAAADd\nEWcAAIwhzgAAGEOcAQAwhjgDAGAMcQYAwBjfYA/wP6FQq6vrpaQkKhxud3VNr2EPo8ceuoN9jB57\nGD239zAQSL7hsSH7ztnnix/sEWIeexg99tAd7GP02MPo3cw9HLJxBgAgVhFnAACMIc4AABhDnAEA\nMIY4AwBgDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAwxsxvpYI9b1Z/ota2DlfX\nnDPldlfXs449BOAE75wBADCGOAMAYAxxBgDAGOIMAIAxxBkAAGOIMwAAxhBnAACMIc4AABhDnAEA\nMIY4AwBgDHEGAMAY4gwAgDHEGQAAY4gzAADG8CsjAQBD0rG/N7q6Xu68u11dry+8cwYAwBjiDACA\nMcQZAABjPtPfOdfV1WnVqlVavny5CgoKtHbtWoXDYUnSpUuXNGXKFJWUlEQ+/7XXXtNvfvMbjRs3\nTpI0a9YsPfroowMwPgAAQ0+/cW5vb1dJSYkyMjIi9+3Zsyfy8eOPP67c3Nwej8vJydFjjz3m0pgA\nAHhHv5e1/X6/ysrKFAwGexz7+OOP1draqsmTJw/IcAAAeFG/cfb5fEpISOj12O9+9zsVFBT0euzk\nyZNasWKFli1bpg8++CC6KQEA8BDH3+d89epVvffeeyouLu5x7Bvf+IZSU1M1Z84cvf/++3rsscf0\nl7/8pc/1UlIS5fPFOx2nV4FAsqvreU59i5KTev+DmVOe+5qwh67x6ut2k9f20O1zT7p5e+g4zqdO\nnbrh5ez09HSlp6dLkqZOnaqLFy+qs7NT8fE3jm843O50lF4FAskKhVpdXdOLWts6XF3Pi18T9jB6\nnM/R8+Ieun3uSe6ef32F3vG3Uv3jH//Q3Xf3/tNSysrK9Prrr0v677/0Tk1N7TPMAADgU/2+c66t\nrVVpaakaGxvl8/lUVVWlvXv3KhQKRb5V6n8effRRPfvss3rggQe0adMmvfLKK7p+/bq2bds2YC8A\nAIChJq6rq6trsIeQ3L9U58VLOG57r77F9ctCc6bc7up61rGH7uB8jp4X93Agfra2+cvaAABgYBBn\nAACMIc4AABhDnAEAMIY4AwBgDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAwhjgD\nAGAMcQYAwBjiDACAMcQZAABjiDMAAMYQZwAAjCHOAAAYQ5wBADCGOAMAYAxxBgDAGOIMAIAxxBkA\nAGOIMwAAxhBnAACMIc4AABhDnAEAMOYzxbmurk7Z2dk6dOiQJGnLli164IEHVFhYqMLCQh07dqzH\nY7Zv3668vDzl5+fr9OnTrg4NAMBQ5uvvE9rb21VSUqKMjIxu9//85z/X3Llze33MyZMndfbsWZWX\nl+ujjz7SE088ofLycncmBgBgiOv3nbPf71dZWZmCweBnXrS6ulrZ2dmSpPT0dF2+fFltbW3OpwQA\nwEP6jbPP51NCQkKP+w8dOqSlS5dqw4YNunjxYrdjzc3NSklJidxOTU1VKBRyYVwAAIa+fi9r9+Z7\n3/ueRo4cqXvuuUfPP/+8nnnmGT355JM3/Pyurq5+10xJSZTPF+9knBsKBJJdXc9z6luUnNTzD2bR\n8NzXhD10xZvVn7i63v0Z411dL1Z47b8dt8896ebtoaM4//+/f87KylJxcXG348FgUM3NzZHbFy5c\nUCAQ6HPNcLjdySg3FAgkKxRqdXVNL2pt63B1PS9+TdhDd7i5j17cQy/+P9Htc09y97+dvkLv6Fup\nfvazn6mhoUGSVFNTowkTJnQ7npmZqaqqKknSmTNnFAwGlZSU5OSpAADwnH7fOdfW1qq0tFSNjY3y\n+XyqqqpSQUGB1q9fry9+8YtKTEzUjh07JEkbNmzQjh07NG3aNE2cOFH5+fmKi4vT1q1bB/yFAAAw\nVPQb50mTJungwYM97l+wYEGP+3bv3h35uKioKMrRAADwJn5CGAAAxhBnAACMIc4AABhDnAEAMIY4\nAwBgDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAwhjgDAGAMcQYAwBjiDACAMcQZ\nAABjiDMAAMYQZwAAjCHOAAAYQ5wBADCGOAMAYAxxBgDAGOIMAIAxxBkAAGOIMwAAxvgGewAAwMB7\ns/oTtbZ1uLbenCm3u7YWeuKdMwAAxhBnAACMIc4AABjzmeJcV1en7OxsHTp0SJJ0/vx5LV++XAUF\nBVq+fLlCoVC3z6+pqdHMmTNVWFiowsJClZSUuD85AABDVL//IKy9vV0lJSXKyMiI3Pf000/rkUce\nUU5Ojn7/+9/rpZde0ubNm7s9bsaMGdqzZ4/7EwMAMMT1+87Z7/errKxMwWAwct/WrVu1YMECSVJK\nSoouXbo0cBMCAOAx/b5z9vl88vm6f1piYqIkqbOzUy+//LJWr17d43H19fVauXKlLl++rDVr1igz\nM7PP50lJSZTPF/95Zu9XIJDs6nqeU9+i5KQEV5f03NeEPXSHy/vIHkYvFvbQ7XNPunmv2/H3OXd2\ndmrz5s2aOXNmt0vekjR+/HitWbNGCxcuVENDg5YuXarDhw/L7/ffcL1wuN3pKL0KBJIVCrW6uqYX\nufl9kZI8+TVhD93h5j6yh9GLhT10+9yT3H3dfYXe8b/Wfvzxx3XXXXdpzZo1PY6lpaUpJydHcXFx\nGjdunEaPHq2mpianTwUAgKc4inNlZaW+8IUvaO3atTc8fuDAAUlSKBRSS0uL0tLSnE8JAICH9HtZ\nu7a2VqWlpWpsbJTP51NVVZVaWlp0yy23qLCwUJKUnp6u4uJibdiwQTt27FBWVpaKiop05MgRXbt2\nTcXFxX1e0gYAAJ/qN86TJk3SwYMHP9Niu3fvjny8f/9+51MBAOBh/IQwAACMIc4AABhDnAEAMIY4\nAwBgDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAwhjgDAGAMcQYAwBjiDACAMcQZ\nAABjiDMAAMYQZwAAjPEN9gAD5c3qT9Ta1uHaenOm3O7aWgAA9IV3zgAAGEOcAQAwhjgDAGAMcQYA\nwBjiDACAMcQZAABjiDMAAMYQZwAAjCHOAAAYQ5wBADDmM8W5rq5O2dnZOnTokCTp/PnzKiws1JIl\nS7Ru3TpdvXq1x2O2b9+uvLw85efn6/Tp0+5ODQDAENZvnNvb21VSUqKMjIzIfXv27NGSJUv08ssv\n66677lJFRUW3x5w8eVJnz55VeXm5tm3bpm3btrk/OQAAQ1S/cfb7/SorK1MwGIzcV1NTo+9+97uS\npLlz56q6urrbY6qrq5WdnS1JSk9P1+XLl9XW1ubm3AAADFn9xtnn8ykhIaHbfVeuXJHf75ckjRo1\nSqFQqNvx5uZmpaSkRG6npqb2+BwAANC7qH9lZFdXlyufk5KSKJ8vPtpxPlXfouSkhP4/7zMKBJJd\nWytmuLyHkgf3kT10B+dz9Dy4h26fe9LNe92O4pyYmKiOjg4lJCSoqamp2yVvSQoGg2pubo7cvnDh\nggKBQJ9rhsPtTkbpk5u/zzkUanVtrVji5h5K3txH9tAdnM/R89oeun3uSe6+7r5C7+hbqWbNmqWq\nqipJ0uHDh3Xvvfd2O56ZmRk5fubMGQWDQSUlJTl5KgAAPKffd861tbUqLS1VY2OjfD6fqqqqtGvX\nLm3ZskXl5eW67bbb9NBDD0mSNmzYoB07dmjatGmaOHGi8vPzFRcXp61btw74CwEAYKjoN86TJk3S\nwYMHe9z/0ksv9bhv9+7dkY+LioqiHA0AAG/iJ4QBAGAMcQYAwBjiDACAMcQZAABjiDMAAMYQZwAA\njCHOAAAYQ5wBADCGOAMAYAxxBgDAGOIMAIAxxBkAAGOIMwAAxhBnAACMIc4AABhDnAEAMIY4AwBg\nDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAwhjgDAGAMcQYAwBjiDACAMcQZAABj\niDMAAMb4nDzoT3/6kyorKyO3a2tr9f7770duT5w4UdOmTYvc/u1vf6v4+PgoxgQAwDscxTk3N1e5\nubmSpJMnT+qvf/1rt+NJSUk6ePBg9NMBAOBBUV/W3rdvn1atWuXGLAAAQA7fOf/P6dOnNXbsWAUC\ngW73X716VRs3blRjY6MWLFigH/7wh/2ulZKSKJ/PxUvf9S1KTkpwbblAINm1tWKGy3soeXAf2UN3\ncD5Hz4N76Pa5J9281x1VnCsqKrRo0aIe92/evFkPPvig4uLiVFBQoG9961v6+te/3uda4XB7NKP0\nqrWtw7W1QqFW19aKJW7uoeTNfWQP3cH5HD2v7aHb557k7uvuK/RRXdauqanR1KlTe9y/ePFiDR8+\nXImJiZo5c6bq6uqieRoAADzFcZybmpo0fPhw+f3+bvd//PHH2rhxo7q6unT9+nX97W9/04QJE6Ie\nFAAAr3B8WTsUCik1NTVy+/nnn9f06dM1depUjRkzRg8//LCGDRumrKwsTZ482ZVhAQDwAsdxnjRp\nkl544YXI7Z/85CeRjzdt2hTdVAAAeBg/IQwAAGOIMwAAxhBnAACMIc4AABhDnAEAMIY4AwBgDHEG\nAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAwhjgDAGAMcQYAwBjiDACAMcQZAABjiDMA\nAMYQZwAAjCHOAAAYQ5wBADCGOAMAYAxxBgDAGOIMAIAxxBkAAGOIMwAAxhBnAACMIc4AABjjc/Kg\nmpoarVu3ThMmTJAkfeUrX9GvfvWryPF33nlHv/71rxUfH6/Zs2dr9erV7kwLAIAHOIqzJM2YMUN7\n9uzp9dhTTz2lAwcOKC0tTQUFBVqwYIG+/OUvOx4SAAAvcf2ydkNDg0aMGKGxY8dq2LBhuu+++1Rd\nXe320wAAMGQ5jnN9fb1WrlypxYsX6/jx45H7Q6GQUlNTI7dTU1MVCoWimxIAAA9xdFl7/PjxWrNm\njRYuXKiGhgYtXbpUhw8flt/vdzxISkqifL54x4/vob5FyUkJri0XCCS7tlbMcHkPJQ/uI3voDs7n\n6HlwD90+96Sb97odxTktLU05OTmSpHHjxmn06NFqamrSnXfeqWAwqObm5sjnNjU1KRgM9rtmONzu\nZJQ+tbZ1uLZWKNTq2lqxxM09lLy5j+yhOzifo+e1PXT73JPcfd19hd7RZe3KykodOHBA0n8vY7e0\ntCgtLU2SdMcdd6itrU3nzp3T9evXdfToUWVmZjp5GgAAPMnRO+esrCwVFRXpyJEjunbtmoqLi/X6\n668rOTlZ8+bNU3FxsTZu3ChJysnJ0Ze+9CVXhwYAYChzFOekpCTt37//hsenT5+u8vJyx0MBAOBl\n/IQwAACMIc4AABhDnAEAMIY4AwBgDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAw\nhjgDAGAMcQYAwBjiDACAMcQZAABjiDMAAMYQZwAAjCHOAAAYQ5wBADCGOAMAYAxxBgDAGOIMAIAx\nxBkAAGOIMwAAxhBnAACMIc4AABhDnAEAMIY4AwBgDHEGAMAYn9MH7ty5U++9956uX7+un/70p5o/\nf37kWFZWlsaMGaP4+HhJ0q5du5SWlhb9tAAAeICjOJ84cUIffvihysvLFQ6HtWjRom5xlqSysjIN\nHz7clSEBAPASR3GePn26Jk+eLEm69dZbdeXKFXV2dkbeKQMAAOccxTk+Pl6JiYmSpIqKCs2ePbtH\nmLdu3arGxkZ985vf1MaNGxUXF9fnmikpifL5XIx7fYuSkxJcWy4QSHZtrZjh8h5KHtxH9tAdnM/R\n8+Aeun3uSTfvdTv+O2dJeuutt1RRUaEXX3yx2/1r167VvffeqxEjRmj16tWqqqrS/fff3+da4XB7\nNKP0qrWtw7W1QqFW19aKJW7uoeTNfWQP3cH5HD2v7aHb557k7uvuK/SO/7X222+/rf3796usrEzJ\nyd2f4KGHHtKoUaPk8/k0e/Zs1dXVOX0aAAA8x1GcW1tbtXPnTj333HMaOXJkj2MrVqzQ1atXJUmn\nTp3ShAkTop8UAACPcHRZ+4033lA4HNb69esj933729/WV7/6Vc2bN0+zZ89WXl6ebrnlFn3ta1/r\n95I2AAD4lKM45+XlKS8v74bHly1bpmXLljkeCgAAL+MnhAEAYAxxBgDAGOIMAIAxxBkAAGOIMwAA\nxhBnAACMIc4AABhDnAEAMIY4AwBgDHEGAMAY4gwAgDHEGQAAY4gzAADGEGcAAIwhzgAAGEOcAQAw\nhjgDAGAMcQYAwBjiDACAMcQZAABjiDMAAMYQZwAAjCHOAAAYQ5wBADCGOAMAYAxxBgDAGOIMAIAx\nxBkAAGMcx3n79u3Ky8tTfn6+Tp8+3e3YO++8o4cfflh5eXnat29f1EMCAOAljuJ88uRJnT17VuXl\n5dq2bZu2bdvW7fhTTz2lvXv36g9/+IOOHz+u+vp6V4YFAMALHMW5urpa2dnZkqT09HRdvnxZbW1t\nkqSGhgaNGDFCY8eO1bBhw3TfffepurravYkBABjiHMW5ublZKSkpkdupqakKhUKSpFAopNTU1F6P\nAQCA/vncWKSrqyvqNQKBZBcm+dT9Lq/nRexh9NhDd7CP0fPiHubOu9v1Nd1u1Y04euccDAbV3Nwc\nuX3hwgUFAoFejzU1NSkYDEY5JgAA3uEozpmZmaqqqpIknTlzRsFgUElJSZKkO+64Q21tbTp37pyu\nX7+uo0ePKjMz072JAQAY4uK6HF6T3rVrl959913FxcVp69at+uCDD5ScnKx58+bp1KlT2rVrlyRp\n/vz5WrFihatDAwAwlDmOMwAAGBj8hDAAAIwhzgAAGDMk41xXV6fs7GwdOnRosEeJWTt37lReXp5+\n8IMf6PDhw4M9Tsy5cuWK1q1bp4KCAuXm5uro0aODPVLM6ujoUHZ2tl577bXBHiXm1NTUaObMmSos\nLFRhYaFKSkoGe6SYVVlZqQcffFDf//73dezYsQF/Ple+z9mS9vZ2lZSUKCMjY7BHiVknTpzQhx9+\nqPLycoXDYS1atEjz588f7LFiytGjRzVp0iT9+Mc/VmNjo370ox9p7ty5gz1WTHr22Wc1YsSIwR4j\nZs2YMUN79uwZ7DFiWjgc1r59+/Tqq6+qvb1de/fu1Zw5cwb0OYdcnP1+v8rKylRWVjbYo8Ss6dOn\na/LkyZKkW2+9VVeuXFFnZ6fi4+MHebLYkZOTE/n4/PnzSktLG8RpYtdHH32k+vr6Af8fIdCX6upq\nZWRkKCkpSUlJSTflCsSQu6zt8/mUkJAw2GPEtPj4eCUmJkqSKioqNHv2bMLsUH5+voqKivTEE08M\n9igxqbS0VFu2bBnsMWJafX29Vq5cqcWLF+v48eODPU5MOnfunDo6OrRy5UotWbLkpvy+iCH3zhnu\neeutt1RRUaEXX3xxsEeJWa+88or++c9/atOmTaqsrFRcXNxgjxQz/vznP2vKlCm68847B3uUmDV+\n/HitWbNGCxcuVENDg5YuXarDhw/L7/cP9mgx59KlS3rmmWf0r3/9S0uXLtXRo0cH9HwmzujV22+/\nrf379+uFF15QcrL3fiZvtGprazVq1CiNHTtW99xzjzo7O3Xx4kWNGjVqsEeLGceOHVNDQ4OOHTum\nf//73/L7/RozZoxmzZo12KPFjLS0tMhfsYwbN06jR49WU1MTf+D5nEaNGqWpU6fK5/Np3LhxGj58\n+ICfz0Pusjai19raqp07d+q5557TyJEjB3ucmPTuu+9Grjg0Nzervb29229yQ/+efvppvfrqq/rj\nH/+o3NxcrVq1ijB/TpWVlTpw4ICk//7GwJaWFv79gwPf+c53dOLECf3nP/9ROBy+KefzkHvnXFtb\nq9LSUjU2Nsrn86mqqkp79+4lMp/DG2+8oXA4rPXr10fuKy0t1W233TaIU8WW/Px8/eIXv9CSJUvU\n0dGhJ598UsOG8Wdh3FxZWVkqKirSkSNHdO3aNRUXF3NJ24G0tDQtWLBAjzzyiCTpl7/85YCfz/z4\nTgAAjOGP8gAAGEOcAQAwhjgDAGAMcQYAwBjiDACAMcQZAABjiDMAAMYQZwAAjPk/XtYpMkHW9esA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "KBIrNBNtKPGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}